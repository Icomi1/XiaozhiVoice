# 声纹识别全流程 GUI界面

## 0 数据集

使用的是[中文语音语料数据集](https://github.com/fighting41love/zhvoice) 的子集（zhaidatatang），中文语音语料数据集数据集一共有3242个人的语音数据，有1130000+条语音数据。大家也可以用自己的数据集。

## 1 数据处理

将自己的数据集的文件夹组织形式处理成如下格式即可：

```
yourdatasets:
		speaker1:
			xxx.wav(/mp3)
			xxx.wav(/mp3)
			xxx.wav(/mp3)
		speaker2:
		……
		speakerN:
```

即同一个说话人的音频放在同一个文件夹下，文件夹的命名表示说话人，命名不能重复。运行`create_data.py`文件即可进行数据处理。按照9:1的比例划分训练集和测试集，数据处理的结果会生成一个h5文件，其中保存着每条音频的路径、特征和类别（说话人）。如果是mp3格式的音频，数据预处理的时间会变长。这一步数据量很大，需要耐心等待。



## 2 训练

打开`train.py`文件，设置好下列参数：

![1](readme_assert\1.png)

每个参数都有相应的解释。设置完后，运行`train.py`文件开始训练，等待训练结果。

![Snipaste_2022-04-16_14-12-24](readme_assert\2.png)



## 3 评估

训练结束后，会保存一个最优的模型文件。使用该模型对音频特征进行两两对比，阈值从0到1,步长为0.01进行控制，找到最佳的阈值并计算准确率。

一般来说，两条音频的相似度大于0.5就可以是认为同一个说话人。但为了更好的效果，我们用`eval.py`文件来寻找最佳阈值。

打开`eval.py`文件，设置好参数后，运行：

![Snipaste_2022-04-16_14-12-05](readme_assert\3.png)



## 4 声纹对比

声纹对比就是对比两条音频是不是属于同一个说话人。打开`infer_contrast.py`文件，配置好参数，运行，会输出结果。



## 5 声纹识别

声纹识别就是识别一条音频是否属于声纹库中已经注册的用户。如果有用户需要通过声纹登录，就需要拿到用户的语音和语音库中的语音进行声纹对比，如果对比成功，那就相当于登录成功并且获取用户注册时的信息数据。

同时我们还需要有注册功能，就是将新的用户添加到声纹库中。声纹库是`SpeakerDatabase`文件夹

这部分功能由`infer_recognition.py`文件实现。打开文件，配置好参数后，运行。即可在命令行中根据提示进行注册和识别操作：

![image-20220416152857985](readme_assert\4.png)



## 6 GUI界面演示

运行`myAPP.py`文件，即可打开GUI界面，点击相应按钮进行操作。

![image-20220416153036047](readme_assert\5.png)