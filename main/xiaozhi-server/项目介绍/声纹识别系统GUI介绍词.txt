下面给大家介绍一个声纹识别系统，也叫说话人识别系统。带有G UI界面。
这个系统包括数据处理、训练、评估、声纹对比、声纹识别的全部流程，并且包含一个G UI界面。
接下来给大家展示一下用G UI界面实现声纹注册、声纹识别的过程。
界面左侧是声纹库，里面包含了已经注册过的用户信息。通过右侧操作，我们可以添加新的用户进入声纹库。添加的方式可以选择现场录音，可以选择已经录好的音频。
同样的，执行声纹识别也可以选择已经录好的音频或者是现场录音。
接下来展示一下声纹对比的功能。声纹对比就是比较两条音频是否属于同一个说话人。通过界面下方按钮，选择两条音频，进行对比。
接下来介绍一下项目的代码。
首先是数据处理。将自己的数据集的文件夹组织形式处理成如下格式即可，即同一个说话人的音频放在同一个文件夹下，文件夹的命名表示说话人，命名不能重复。运行create_data.py文件即可进行数据处理。按照9:1的比例划分训练集和测试集，数据处理的结果会生成一个h5文件，其中保存着每条音频的路径、特征和类别（说话人）。
如果是mp3格式的音频，数据预处理的时间会变长。这一步数据量很大，需要耐心等待。
然后是训练。打开train.py文件，设置好下列参数，每个参数都有相应的解释。设置完后，运行train.py文件开始训练，等待训练结果。
然后是评估模型。训练结束后，会保存一个最优的模型文件。使用该模型对音频特征进行两两对比，阈值从0到1,步长为0.01进行控制，找到最佳的阈值并计算准确率。
一般来说，两条音频的相似度大于0.5就可以是认为同一个说话人。但为了更好的效果，我们用`eval.py`文件来寻找最佳阈值。打开eval.py文件，设置好参数后，运行即可。
然后就可以用训练好的模型进行声纹对比和声纹识别了，二者的代码分别在infer_contrast.py文件和infer_recognition.py文件中。